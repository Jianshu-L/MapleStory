{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd5367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pymdptoolbox numpy\n",
    "import numpy as np\n",
    "import mdptoolbox\n",
    "\n",
    "# ========== 参数 ==========\n",
    "max_tries = 7\n",
    "target_atk = 14\n",
    "A_max = 30          # 攻击状态上限（防越界，取比目标稍大）\n",
    "gamma = 1.0         # 最大化成功概率\n",
    "reward_success = 1.0\n",
    "\n",
    "# 四个动作：A5, A2, B5, B2 及其成功率、加成、失败时是否带消失风险\n",
    "# 格式: (success_prob, delta_on_success, fail_destroy_prob)\n",
    "# 失败不加成（+0）；若 fail_destroy_prob > 0，则失败后以该概率进入 GONE，否则留在 (t+1, atk)\n",
    "ACTIONS = [\n",
    "    (\"A5\", 0.11, 3, 0.0),  # 成功10% +5；失败不消失\n",
    "    (\"A2\", 0.66, 2, 0.0),  # 成功60% +2；失败不消失\n",
    "    (\"B5\", 0.33, 3, 0.5),  # 成功30% +5；失败时50%消失\n",
    "    (\"B2\", 0.77, 2, 0.5),  # 成功70% +2；失败时50%消失\n",
    "]\n",
    "nA = len(ACTIONS)\n",
    "\n",
    "# ========== 状态编码 ==========\n",
    "id_map = {}\n",
    "states = []\n",
    "for t in range(max_tries + 1):\n",
    "    for atk in range(A_max + 1):\n",
    "        sid = len(id_map)\n",
    "        id_map[(t, atk)] = sid\n",
    "        states.append((t, atk))\n",
    "\n",
    "S_goal = len(id_map); id_map[\"GOAL\"] = S_goal\n",
    "S_gone = S_goal + 1;  id_map[\"GONE\"] = S_gone\n",
    "S_dead = S_goal + 2;  id_map[\"DEAD\"] = S_dead\n",
    "\n",
    "nS = len(id_map)\n",
    "\n",
    "def clamp_atk(a):\n",
    "    return min(a, A_max)\n",
    "\n",
    "# ========== 初始化 P, R ==========\n",
    "P = [np.zeros((nS, nS)) for _ in range(nA)]\n",
    "R = [np.zeros((nS, nS)) for _ in range(nA)]\n",
    "\n",
    "def add_transition(a_idx, s_from, s_to, prob, reward):\n",
    "    if prob <= 1e-15:  # 避免浮点噪声\n",
    "        return\n",
    "    P[a_idx][s_from, s_to] += prob\n",
    "    # 仅在到达 GOAL 的转移上给奖励 1\n",
    "    if reward != 0.0:\n",
    "        R[a_idx][s_from, s_to] = reward\n",
    "\n",
    "for t in range(max_tries + 1):\n",
    "    for atk in range(A_max + 1):\n",
    "        s = id_map[(t, atk)]\n",
    "\n",
    "        # 若已达标，吸收到 GOAL\n",
    "        if atk >= target_atk:\n",
    "            for a_idx in range(nA):\n",
    "                add_transition(a_idx, s, S_goal, 1.0, 0.0)\n",
    "            continue\n",
    "\n",
    "        # 若次数用尽且未达标，吸收到 DEAD\n",
    "        if t >= max_tries:\n",
    "            for a_idx in range(nA):\n",
    "                add_transition(a_idx, s, S_dead, 1.0, 0.0)\n",
    "            continue\n",
    "\n",
    "        t_next = t + 1\n",
    "\n",
    "        # 为每个动作构造转移\n",
    "        for a_idx, (name, p_succ, delta, fail_destroy_prob) in enumerate(ACTIONS):\n",
    "            p_fail = 1.0 - p_succ\n",
    "\n",
    "            # 成功分支：atk 增加 delta；若达标则进入 GOAL，否则到 (t+1, atk+delta)\n",
    "            atk_succ = clamp_atk(atk + delta)\n",
    "            if atk_succ >= target_atk:\n",
    "                add_transition(a_idx, s, S_goal, p_succ, reward_success)\n",
    "            else:\n",
    "                s_next = id_map[(t_next, atk_succ)]\n",
    "                add_transition(a_idx, s, s_next, p_succ, 0.0)\n",
    "\n",
    "            # 失败分支：+0\n",
    "            if p_fail > 0:\n",
    "                # 部分失败直接消失\n",
    "                if fail_destroy_prob > 0:\n",
    "                    add_transition(a_idx, s, S_gone, p_fail * fail_destroy_prob, 0.0)\n",
    "                    p_fail_keep = p_fail * (1.0 - fail_destroy_prob)\n",
    "                else:\n",
    "                    p_fail_keep = p_fail\n",
    "\n",
    "                # 失败但未消失：停留在攻击不变、次数+1\n",
    "                if p_fail_keep > 0:\n",
    "                    s_fail_keep = id_map[(t_next, clamp_atk(atk))]\n",
    "                    add_transition(a_idx, s, s_fail_keep, p_fail_keep, 0.0)\n",
    "\n",
    "# 终止态吸收\n",
    "for a_idx in range(nA):\n",
    "    P[a_idx][S_goal, S_goal] = 1.0\n",
    "    P[a_idx][S_gone, S_gone] = 1.0\n",
    "    P[a_idx][S_dead, S_dead] = 1.0\n",
    "    # 终止奖励默认保持 0（除了到达 GOAL 的那一下已经给了 1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0549a1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: check conditions of convergence. With no discount, convergence can not be assumed.\n",
      "Initial best action (0=A5,1=A2,2=B5,3=B2): 1\n",
      "Initial success probability: 0.19977434999999996\n",
      "(t=0, atk=0) best action: 1\n",
      "(t=1, atk=0) best action: 2\n",
      "(t=2, atk=2) best action: 2\n",
      "(t=3, atk=4) best action: 2\n",
      "(t=4, atk=6) best action: 2\n",
      "(t=5, atk=10) best action: 1\n",
      "(t=6, atk=12) best action: 3\n"
     ]
    }
   ],
   "source": [
    "# ========== 值迭代求解 ==========\n",
    "vi = mdptoolbox.mdp.ValueIteration(P, R, discount=gamma)\n",
    "vi.run()\n",
    "\n",
    "V = vi.V            # 状态的最大成功概率\n",
    "policy = vi.policy  # 最优动作：0=A5, 1=A2, 2=B5, 3=B2\n",
    "\n",
    "# 初始状态的结果\n",
    "s0 = id_map[(0, 0)]\n",
    "print(\"Initial best action (0=A5,1=A2,2=B5,3=B2):\", policy[s0])\n",
    "print(\"Initial success probability:\", V[s0])\n",
    "\n",
    "# 查看某些中间状态的最优动作\n",
    "def best_action_at(t, atk):\n",
    "    return policy[id_map[(t, atk)]]\n",
    "\n",
    "probes = [(0,0), (1,0), (2,2), (3,4), (4,6), (5,10), (6,12)]\n",
    "for t_probe, atk_probe in probes:\n",
    "    print(f\"(t={t_probe}, atk={atk_probe}) best action:\", best_action_at(t_probe, atk_probe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f525e0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09573e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5e2eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "possible_scrolls_results = [3, 2, 0]\n",
    "num_slots = 3\n",
    "for slot_i in range(num_slots):\n",
    "    all_possible_states = [3, 2, 0, -1]\n",
    "    states.append(all_possible_states)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c154096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0850d46a",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73a43dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f86ebf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage: 2, policy: [0, 1, 0]\n",
      "stage: 1, policy: [0, 0, 0]\n",
      "stage: 0, policy: [0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import mdptoolbox, mdptoolbox.example\n",
    "\n",
    "P, R = mdptoolbox.example.forest()\n",
    "fh = mdptoolbox.mdp.FiniteHorizon(P, R, 0.9, 3)\n",
    "fh.setVerbose()\n",
    "fh.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b7389e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fh.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49d2c540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.1, 0.9, 0. ],\n",
       "        [0.1, 0. , 0.9],\n",
       "        [0.1, 0. , 0.9]],\n",
       "\n",
       "       [[1. , 0. , 0. ],\n",
       "        [1. , 0. , 0. ],\n",
       "        [1. , 0. , 0. ]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502806c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5679d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_action= 4\n",
    "num_steps = 7\n",
    "\n",
    "num_state = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4afef58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 1.],\n",
       "       [4., 2.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91eb4f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.6973, 0.81  , 0.    , 0.    ],\n",
       "       [5.9373, 3.24  , 1.    , 0.    ],\n",
       "       [9.9373, 7.24  , 4.    , 0.    ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fh.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c52d156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MDP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
